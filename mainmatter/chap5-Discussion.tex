% Chapter 5: Discussion
\section{Discussion}
We sought to address whether covariate-adaptive allocation followed by re-randomization conferred any statistical power advantage relative to complete randomization, stratified block randomization, and covariate-adaptive allocation using model-based inference.
By simulating both binary and continuous outcomes and prognostic factors, our study considered a broad range of settings compared to previous work.

We specified the models correctly as simulated. 
As mentioned in the previous section on subsetted simulations, coverage probability and bias were inflated due to low event rates and their corresponding effect on logistic regression model output.
Our simulation exclusion criteria is similar to Kalish and Begg (1987) which excluded any analysis with a singular design matrix or if any response by treatment count was zero.
All issues with coverage or bias were ameliorated after requiring sufficient events for convergence, either by subsetting on previously mentioned criterion or increasing trial size.
When either the outcome prevalence or trial size was increased, bias approached zero and coverage probability converged to the nominal rate.
Size was also well controlled when convergence was not an issue.

Re-randomization inference tends to be more powerful relative to model-based analysis for selected conditions, particularly for binary outcomes where the marginal outcome prevalence or overall trial size is low.
Similarly, not adjusting for prognostic factors resulted in more conservative inference regardless of the allocation method used.  
Our findings match the consensus that ignoring prognostic factors used in allocation scheme leads to conservative inference (Forsythe 1985, Kalish and Begg 1987, Scott et. al 2002, Shao 2010, Ma 2015).
Adjusting for prognostic factors used in the allocation procedure in linear models was also found necessary to obtain proper size by Birkett (1985), Forsythe (1987), and Lachin, Matts, Wei (1988).

Previous study on the use of rerandomization analysis states while it is often not adopted because of its computational complexity, it remains a useful alternative to model-based inference when drift is present or when implementing covariate adaptive allocation methods with greater degrees of deterministic allocations.
Simon (1979) state the importance of using such approaches for calculating the appropriate randomization significance level to obtain the full benefit of the power gain with such adaptive procedures (Birkett 1985).
Model-based analysis assumes a time homogeneous population with respect to the outcome measure, which may not always be satisfied in practice (Lachin, Matts, Wei 1988)
Scott (2002), Browne et. al (2005), and Simon and Simon (2011) recommend rerandomization analysis to protect against type 1 error inflation if there may be time trends in the outcome measure independent of the measured prognostic factors.
For survival outcomes, Xu et. al (2016) found rerandomization to be just as powerful as the stratified log-rank test for estimating adjusted treatment effect hazard ratios.

One limitation of our study is that our simulation considered a fixed number of independent prognostic factors.
To compare stratification with CAA under realistic use cases, we could have additionally considered settings with multiple (potentially correlated) prognostic factors, where it would be infeasible to include all baseline variables in stratified allocation.  
Several authors (Birkett 1987, Scott et. al 2002) suggest that these settings are where minimization outperforms stratification.

In the continuous prognostic factor settings, we also only considered Normally distributed random variables and dichotomized them by their median for determinining groups for balanced allocations.
The general consensus is to incorporate balancing variables into the analysis 'as-is'; however in our simulations the dichotomized variables were used for blocking and adaptive allocation and the continuous measure used in the analysis.
Future methods could consider using an approach of balancing means of prognostic variables across treatment groups, in order to leverage additional information lost by dichotomizing continuous prognostic variables by arbitrary cutpoints.
Aickin (1998, 2002, 2009) proposed a method for balancing continuous covariates; they were not considered since they require specifying a model between outcome and prognostic factors for the allocation procedure.

Another limitation of our findings is how we did not explicitly model drift, or a change in the outcome prevalence over time that is unrelated to measured prognostic variables.
Not accounting for drift could lead to potential bias (Scott 2002, Browne et. al 2005, and Simon and Simon 2011).
This phenomenon is often encountered in practice and is a major consideration for adopting stratification or covariate adaptive allocation methods.
Several authors (Halpern and Brown 1986, Green, McEntegart, Byrom, Ghani, Shepherd 2001) claim that classical (model-based) analysis yields similar conclusions to rerandomization except in specific circumstances such as drift.
Future simulations modeling drift in these settings could potentially assess the relative performance of stratified block randomization and CAA relative to complete randomization for controlling the effects of drift.

There are yet undescribed reasons to consider implementing covariate adaptive allocation with re-randomization as a design and analytic tool.
Covariate adaptive allocation procedures are designed to induce balance in prognostic factors, particularly to hedge against chance imbalances that could be seen as compromising the impact of study results. 
Heritier et. al (2005) note having more homogeneous subgroups does not necessarily yield more efficient inference outside linear regression.
However, if subgroup analysis is an important endpoint then allocation procedures ensuring balanced treatment allocations within strata can be useful to facilitate and maximize power for subset analyses (Lachin, Matts, Wei 1988, Emerson 2010).

Using covariate adaptive allocation procedures to control imbalance involves eschewing the benefits of complete randomization in permitting straightforward analysis and interpretation of results.
Complete randomization allows for population model-based analysis, circumventing the need for implementing permutation model-based analysis to obtain proper size.
Permutation model-based analysis can only generate confidence intervals under the null hypothesis (Emerson 2010), and require bootstrap or other resampling techniques to generate confidence intervals for parameter estimates (Ma 2015).

\section{Conclusions}

We have identified conditions under which covariate adaptive allocation followed by rerandomization analysis provides additional power advantages over adjusted model-based methods.
The degree to which pre-randomization stratification and adjustment in the analysis addresses the issues presented by chance imbalance in potential confounding factors is still debated.
When considering between complete or restricted randomization and covariate adaptive allocation methods, careful thought is recommended to identify relevant baseline covariates and to weigh their relative importance for strict balance.
While there may be a modest increase in power from covariate adaptive allocation in some settings, it comes with the potential for added complexity in the analysis and must be implemented judiciously. 

